{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import datetime \n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\stations.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['name','address','lon','lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "f = h5.File(r'C:\\air\\madrid.h5')\n",
    "datasetNames = [n for n in f.keys()]\n",
    "for n in datasetNames:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('C:/air/madrid.h5') as data:\n",
    "    df = data['master']\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('C:/air/madrid.h5') as data:\n",
    "    for k in data.keys():\n",
    "        print('{}: {}'.format(k, ', '.join(data[k].columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('C:/air/madrid.h5') as data:\n",
    "    test = data['28079001']\n",
    "  \n",
    "test.rolling(window=24).mean().plot(figsize=(30, 7), alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partials = list()\n",
    "\n",
    "with pd.HDFStore('C:/air/madrid.h5') as data:\n",
    "    stations = [k[1:] for k in data.keys() if k != '/master']\n",
    "    for station in stations:\n",
    "        df = data[station]\n",
    "        df['station'] = station\n",
    "        partials.append(df)\n",
    "            \n",
    "df = pd.concat(partials, sort=False).sort_index()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['SO_2']=pd.Series(np.where(data2.SO_2.values > 10, 1, 0),\n",
    "          data2.index)\n",
    "data2.head()\n",
    "y = data2['SO_2']\n",
    "y=y.astype('int')\n",
    "x = data2.drop('SO_2',axis=1)\n",
    "\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Best parameters found:\\n', clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import neural_network\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "data2['SO_2']=pd.Series(np.where(data2.SO_2.values > 10, 1, 0),\n",
    "          data2.index)\n",
    "data2.head()\n",
    "y = data2['SO_2']\n",
    "y=y.astype('int')\n",
    "x = data2.drop('SO_2',axis=1)\n",
    "\n",
    "clf = neural_network.MLPClassifier(alpha=0.1, hidden_layer_sizes=(6), max_iter=500, random_state=3, solver='lbfgs')\n",
    "clf.fit(x, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','SO_2','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['PM25']=pd.Series(np.where(data2.PM25.values > 30, 1, 0),\n",
    "          data2.index)\n",
    "data2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20,)\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "y = data2['PM25']\n",
    "y=y.astype('int')\n",
    "x = data2.iloc[:,0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', \n",
    "                        solver= 'sgd')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()\n",
    "data2['PM10']=pd.Series(np.where(data2.PM10.values > 40, 1, 0),\n",
    "          data2.index)\n",
    "data2.head()\n",
    "y = data2['PM10']\n",
    "y=y.astype('int')\n",
    "x = data2.drop('PM10',axis=1)\n",
    "\n",
    "clf = neural_network.MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=100, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "clf.fit(x, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', \n",
    "                        solver= 'sgd')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', \n",
    "                        solver= 'sgd')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','SO_2','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', \n",
    "                        solver= 'sgd')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (50, 100, 50), learning_rate= 'adaptive', \n",
    "                        solver= 'sgd')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.show()\n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "fpr, tpr, thresholds = roc_curve(y_cv, preds)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['CO']\n",
    "y=y.astype('int')\n",
    "x = data2.drop('CO',axis=1)\n",
    "\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "SEED=21\n",
    "mean_auc = 0.0\n",
    "train_auc = 0.0\n",
    "test_auc = 0.0\n",
    "n = 10  \n",
    "for i in range(n):\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    x, y, test_size=.20, random_state=i*SEED)\n",
    "    clf = MLPClassifier(activation= 'relu', alpha= 0.05, hidden_layer_sizes= (50, 100, 50), \n",
    "                        learning_rate= 'adaptive', solver= 'adam')\n",
    "    clf.fit(X_train, y_train) \n",
    "    preds = clf.predict_proba(X_cv)[:, 1]\n",
    "    print(\"Training set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_train, y_train)), i+1 , n)\n",
    "    print(\"roc\")\n",
    "    print (i + 1, n, roc_auc)\n",
    "    print(\"Test set score for Multi Layer Perceptron: {:.3f}\".format(clf.score(X_cv, y_cv)), i+1 , n)\n",
    "    train_auc +=clf.score(X_train, y_train)\n",
    "    test_auc +=clf.score(X_cv, y_cv)\n",
    "    mean_auc += roc_auc\n",
    "   \n",
    "    \n",
    "\n",
    "print (\"mean_auc\", (mean_auc/n))\n",
    "print (\"train_auc\", (train_auc/n))\n",
    "print (\"test_auc\", (test_auc/n))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\air\\csvs\\2004.csv')\n",
    "data1=data[(data.station== 28079001)]\n",
    "data1=data.drop(columns=['BEN','EBE','MXY','NMHC','OXY','PXY','TCH','TOL'])\n",
    "data1 = data1[np.isfinite(data1['CO'])]\n",
    "data1 = data1[np.isfinite(data1['NO_2'])]\n",
    "data1 = data1[np.isfinite(data1['NOx'])]\n",
    "data1 = data1[np.isfinite(data1['O_3'])]\n",
    "data1 = data1[np.isfinite(data1['PM10'])]\n",
    "data1 = data1[np.isfinite(data1['PM25'])]\n",
    "data1 = data1[np.isfinite(data1['SO_2'])]\n",
    "data2=data1.drop(columns=['date','station'])\n",
    "\n",
    "data2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"CO\"] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"NO_2\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"NOx\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"O_3\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"PM10\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"PM25\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot( x=pd.to_datetime(data1['date']).dt.month, y=data1[\"SO_2\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
